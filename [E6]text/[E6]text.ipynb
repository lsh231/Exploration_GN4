{"cells":[{"cell_type":"markdown","source":["# 인공지능 작사가"],"metadata":{"id":"2X3-cZdHQ5rJ"}},{"cell_type":"markdown","source":["### I 다음 am을 쓰면 반 이상은 맞더라"],"metadata":{"id":"oCmJ_Seesgzm"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":554,"status":"ok","timestamp":1652954628836,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"Riw92_v73NIn","outputId":"7391421e-de24-437b-c9f0-6e58a6ad4761"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source 문장: <start> 나는 밥을 먹었다 \n","Target 문장:  나는 밥을 먹었다 <end>\n"]}],"source":["sentence = \" 나는 밥을 먹었다 \"\n","\n","source_sentence = \"<start>\" + sentence\n","target_sentence = sentence + \"<end>\"\n","\n","print(\"Source 문장:\", source_sentence)\n","print(\"Target 문장:\", target_sentence)"]},{"cell_type":"markdown","source":["## 데이터 다듬기"],"metadata":{"id":"gZIkDIOhsuoK"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3373,"status":"ok","timestamp":1652954632655,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"ODhgNATj3gSU","outputId":"9adba57e-f831-4aef-c697-c467fb9b3031"},"outputs":[{"output_type":"stream","name":"stdout","text":["['First Citizen:', 'Before we proceed any further, hear me speak.', '', 'All:', 'Speak, speak.', '', 'First Citizen:', 'You are all resolved rather to die than to famish?', '']\n"]}],"source":["import os, re \n","import numpy as np\n","import tensorflow as tf\n","\n","# 파일을 읽기모드로 열고\n","# 라인 단위로 끊어서 list 형태로 읽어옵니다.\n","file_path =  '/content/drive/MyDrive/AIFFEL/EXP/[E6]text/shakespeare.txt'\n","with open(file_path, \"r\") as f:\n","    raw_corpus = f.read().splitlines()\n","\n","# 앞에서부터 10라인만 화면에 출력해 볼까요?\n","print(raw_corpus[:9])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1652954632656,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"267vuy9n5PeZ","outputId":"830767a8-7e5f-4c3a-a83a-5738e6760286"},"outputs":[{"output_type":"stream","name":"stdout","text":["Before we proceed any further, hear me speak.\n","Speak, speak.\n","You are all resolved rather to die than to famish?\n"]}],"source":["for idx, sentence in enumerate(raw_corpus):\n","    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n","    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n","\n","    if idx > 9: break   # 일단 문장 10개만 확인해 볼 겁니다.\n","        \n","    print(sentence)"]},{"cell_type":"markdown","source":["### 특수 문자 제거"],"metadata":{"id":"dLSb44Z_tSIu"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1652954632658,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"e92dxZC_5z0g","outputId":"5bfce445-19b4-4ba9-ae92-85cf413c2d43"},"outputs":[{"output_type":"stream","name":"stdout","text":["<start> this is sample sentence . <end>\n"]}],"source":["# 입력된 문장을\n","#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n","#     2. 특수문자 양쪽에 공백을 넣고\n","#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n","#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n","#     5. 다시 양쪽 공백을 지웁니다\n","#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n","# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n","def preprocess_sentence(sentence):\n","    sentence = sentence.lower().strip() # 1\n","    \n","    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n","    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n","    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n","    sentence = sentence.strip() # 5\n","    sentence = '<start> ' + sentence + ' <end>' # 6\n","    return sentence\n","\n","# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n","print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":811,"status":"ok","timestamp":1652954633461,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"eRqm-DN18kEm","outputId":"972c713a-e1fe-48bf-a08a-4c519bcbc79f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<start> before we proceed any further , hear me speak . <end>',\n"," '<start> speak , speak . <end>',\n"," '<start> you are all resolved rather to die than to famish ? <end>',\n"," '<start> resolved . resolved . <end>',\n"," '<start> first , you know caius marcius is chief enemy to the people . <end>',\n"," '<start> we know t , we know t . <end>',\n"," '<start> is t a verdict ? <end>',\n"," '<start> no more talking on t let it be done away , away ! <end>',\n"," '<start> one word , good citizens . <end>',\n"," '<start> we are accounted poor citizens , the patricians good . <end>']"]},"metadata":{},"execution_count":5}],"source":["# 여기에 정제된 문장을 모을겁니다\n","corpus = []\n","\n","for sentence in raw_corpus:\n","    # 우리가 원하지 않는 문장은 건너뜁니다\n","    if len(sentence) == 0: continue\n","    if sentence[-1] == \":\": continue\n","    \n","    # 정제를 하고 담아주세요\n","    preprocessed_sentence = preprocess_sentence(sentence)\n","    if len(preprocessed_sentence.split())>15:\n","      continue\n","      \n","    corpus.append(preprocessed_sentence)\n","\n","        \n","# 정제된 결과를 10개만 확인해보죠\n","corpus[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1232,"status":"ok","timestamp":1652954634690,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"lgyDnEGe81BZ","outputId":"0b2e4b33-45cf-4a41-e4e9-6fd7963d4cf2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[   2  141   40 ...    0    0    0]\n"," [   2  110    4 ...    0    0    0]\n"," [   2   11   49 ...    3    0    0]\n"," ...\n"," [   2  147 4524 ...    0    0    0]\n"," [   2   34   71 ...    3    0    0]\n"," [   2  930   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f2e4f66d750>\n"]}],"source":["# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용합니다\n","# 더 잘 알기 위해 아래 문서들을 참고하면 좋습니다\n","# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n","# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n","def tokenize(corpus):\n","    # 7000단어를 기억할 수 있는 tokenizer를 만들겁니다\n","    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n","    # 7000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","        num_words=7000, \n","        filters=' ',\n","        oov_token=\"<unk>\"\n","    )\n","    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n","    tokenizer.fit_on_texts(corpus)\n","    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n","    tensor = tokenizer.texts_to_sequences(corpus)   \n","    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n","    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n","    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n","    \n","    print(tensor,tokenizer)\n","    return tensor, tokenizer\n","\n","tensor, tokenizer = tokenize(corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1652954634690,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"HQMNjoSq9ChN","outputId":"94712b1a-552c-47ec-f0c1-46c76ab8f1a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[   2  141   40  919  140  604    4  124   24  110]\n"," [   2  110    4  110    5    3    0    0    0    0]\n"," [   2   11   49   43 1181  308    9  196   74    9]]\n"]}],"source":["print(tensor[:3, :10])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1652954634691,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"NJn5iv0N9Kco","outputId":"dc839a4e-9e1c-462d-b802-e8b84d40d84a"},"outputs":[{"output_type":"stream","name":"stdout","text":["1 : <unk>\n","2 : <start>\n","3 : <end>\n","4 : ,\n","5 : .\n","6 : the\n","7 : and\n","8 : i\n","9 : to\n","10 : of\n"]}],"source":["for idx in tokenizer.index_word:\n","    print(idx, \":\", tokenizer.index_word[idx])\n","\n","    if idx >= 10: break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1652954634691,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"B_K2HHmB9M6o","outputId":"f62a7d8b-73db-4457-cb1b-69adc013a23d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[  2 141  40 919 140 604   4 124  24 110   5   3   0   0]\n","[141  40 919 140 604   4 124  24 110   5   3   0   0   0]\n"]}],"source":["# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n","# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n","src_input = tensor[:, :-1]  \n","# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n","tgt_input = tensor[:, 1:]    \n","\n","print(src_input[0])\n","print(tgt_input[0])"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","enc_train, enc_val, dec_train, dec_val = train_test_split( src_input, src_input, test_size=0.2, random_state=2)"],"metadata":{"id":"NOEbThcfZZ0-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1219,"status":"ok","timestamp":1652954635905,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"bj3hZH7-9p4R","outputId":"51210ff0-a753-4ca5-9a11-dc40bcc1ae10"},"outputs":[{"output_type":"stream","name":"stdout","text":["92\n"]}],"source":["BUFFER_SIZE = len(src_input)\n","BATCH_SIZE = 256\n","steps_per_epoch = len(src_input) // BATCH_SIZE\n","\n"," # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n","VOCAB_SIZE = tokenizer.num_words + 1   \n","\n","# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n","# 데이터셋에 대해서는 아래 문서를 참고하세요\n","# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n","# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n","dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n","dataset = dataset.shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n","dataset\n","\n","print(steps_per_epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tg8Ya9Tk-NrT"},"outputs":[],"source":["class TextGenerator(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_size, hidden_size):\n","        super().__init__()\n","        \n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n","        self.rnn_1 = tf.keras.layers.LSTM(units = 128, return_sequences=True)\n","        self.rnn_2 = tf.keras.layers.LSTM(units = 128, return_sequences=True)\n","        self.rnn_3 = tf.keras.layers.LSTM(units = 128, return_sequences=True)\n","        self.rnn_4 = tf.keras.layers.LSTM(units = 128 , return_sequences=True)\n","        self.drop  = tf.keras.layers.Dropout(0.5)\n","        self.linear = tf.keras.layers.Dense(vocab_size)\n","        \n","    def call(self, x):\n","        out = self.embedding(x)\n","        out = self.rnn_1(out)\n","        out = self.rnn_2(out)\n","        out = self.rnn_3(out)\n","        out = self.rnn_4(out)\n","        out = self.drop(out)\n","        out = self.linear(out)\n","        \n","        return out\n","    \n","embedding_size = 256\n","hidden_size = 1024\n","model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2396,"status":"ok","timestamp":1652954638297,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"bdnLdLFoDpTK","outputId":"746e0339-90c3-45f7-ba15-245a0d62cf4a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(256, 14, 7001), dtype=float32, numpy=\n","array([[[ 3.56553710e-06, -3.66374024e-06,  3.33420940e-06, ...,\n","          3.91724507e-06, -9.38156177e-07, -7.31692978e-07],\n","        [ 3.98815064e-06, -6.37040330e-06,  1.61752014e-05, ...,\n","          9.90091394e-06, -8.30023782e-06, -2.67064343e-06],\n","        [-1.16395277e-05, -5.70868042e-06,  3.27879352e-05, ...,\n","          1.17832597e-05, -2.12120394e-05, -1.53780329e-05],\n","        ...,\n","        [-6.08520000e-04,  3.10900563e-04,  5.96927421e-05, ...,\n","         -1.29475971e-04, -1.30081215e-04, -1.73603432e-04],\n","        [-6.19922474e-04,  3.75330361e-04,  5.34186147e-05, ...,\n","         -1.14704431e-04, -1.19941440e-04, -1.56632115e-04],\n","        [-6.20294188e-04,  4.28811210e-04,  4.87280377e-05, ...,\n","         -9.28123627e-05, -1.00792269e-04, -1.48267573e-04]],\n","\n","       [[ 3.56553710e-06, -3.66374024e-06,  3.33420940e-06, ...,\n","          3.91724507e-06, -9.38156177e-07, -7.31692978e-07],\n","        [ 1.68586539e-05, -1.51113109e-05,  1.12172684e-05, ...,\n","          9.65161053e-06, -1.34747586e-06, -9.39563233e-06],\n","        [ 3.85093081e-05, -3.39334911e-05,  1.51791164e-05, ...,\n","          1.98410416e-05,  2.33754395e-06, -3.05708199e-05],\n","        ...,\n","        [ 5.12777042e-05, -8.90130686e-05, -4.74203523e-04, ...,\n","         -1.63108067e-04,  2.55457653e-05, -2.33110492e-04],\n","        [ 4.09335844e-05, -9.66154839e-05, -5.93041594e-04, ...,\n","         -1.62778946e-04,  2.05056713e-05, -2.81165674e-04],\n","        [ 3.71240531e-05, -1.06408224e-04, -7.16578332e-04, ...,\n","         -1.57089351e-04,  1.45227214e-05, -3.43307795e-04]],\n","\n","       [[ 3.56553710e-06, -3.66374024e-06,  3.33420940e-06, ...,\n","          3.91724507e-06, -9.38156177e-07, -7.31692978e-07],\n","        [ 1.31131246e-05, -8.35722676e-06,  1.01268934e-05, ...,\n","          1.29402724e-05, -2.83307804e-06, -7.36018683e-06],\n","        [ 2.26340999e-05, -1.80770676e-05,  1.78303471e-05, ...,\n","          2.78757288e-05, -6.50245101e-06, -2.34574909e-05],\n","        ...,\n","        [-1.70424159e-04, -5.11257094e-05,  1.77172857e-04, ...,\n","         -9.67525411e-05,  1.26436507e-05, -9.44310668e-05],\n","        [-2.20452523e-04, -8.19975539e-05,  1.70489104e-04, ...,\n","         -9.92713103e-05,  2.98583909e-05, -1.26274797e-04],\n","        [-2.66905903e-04, -1.13294518e-04,  1.46856182e-04, ...,\n","         -9.10001982e-05,  4.69657534e-05, -1.54023714e-04]],\n","\n","       ...,\n","\n","       [[ 3.56553710e-06, -3.66374024e-06,  3.33420940e-06, ...,\n","          3.91724507e-06, -9.38156177e-07, -7.31692978e-07],\n","        [ 7.35000322e-06, -7.01396220e-06,  1.12590578e-05, ...,\n","          1.25419210e-05, -5.46773026e-06,  3.34363040e-06],\n","        [ 8.77490766e-06, -9.73436909e-06,  1.34168477e-05, ...,\n","          2.83260506e-05, -7.81628387e-06,  1.37627385e-05],\n","        ...,\n","        [-4.55115223e-04,  3.93624759e-05, -3.85156221e-04, ...,\n","          1.95304106e-04, -1.14057921e-05, -4.94261447e-04],\n","        [-5.16214583e-04,  3.66166496e-05, -3.99078417e-04, ...,\n","          2.10047452e-04, -3.06935362e-05, -5.79499581e-04],\n","        [-5.77377737e-04,  3.12214324e-05, -4.08522319e-04, ...,\n","          2.25746364e-04, -4.72953361e-05, -6.50617760e-04]],\n","\n","       [[ 3.56553710e-06, -3.66374024e-06,  3.33420940e-06, ...,\n","          3.91724507e-06, -9.38156177e-07, -7.31692978e-07],\n","        [ 4.86411227e-06, -7.38421704e-06,  2.58383557e-06, ...,\n","          9.06122114e-06,  1.82825704e-06, -5.28978808e-06],\n","        [-6.67330823e-07, -1.32525374e-05, -6.64470281e-06, ...,\n","          1.12272655e-05,  5.93528148e-06, -1.72088421e-05],\n","        ...,\n","        [-6.31641087e-05, -2.11722712e-04, -1.37305979e-04, ...,\n","          1.04801315e-04, -3.68538931e-05, -1.89325714e-04],\n","        [-4.34460635e-05, -2.23904382e-04, -1.41324286e-04, ...,\n","          1.08039530e-04, -4.42869605e-05, -1.87457394e-04],\n","        [-1.32894911e-05, -2.29992715e-04, -1.58828407e-04, ...,\n","          1.06991414e-04, -4.15471586e-05, -1.78675909e-04]],\n","\n","       [[ 3.56553710e-06, -3.66374024e-06,  3.33420940e-06, ...,\n","          3.91724507e-06, -9.38156177e-07, -7.31692978e-07],\n","        [ 1.83092216e-05, -7.39199095e-06,  7.84050098e-06, ...,\n","          7.89280875e-06, -1.30177554e-07, -5.27151224e-06],\n","        [ 3.81715836e-05, -3.29831801e-06,  8.09628364e-06, ...,\n","         -4.25140570e-06,  3.51746417e-06, -1.89596904e-05],\n","        ...,\n","        [ 7.78790854e-05,  2.89161195e-04, -4.21378820e-04, ...,\n","         -2.27139026e-04,  6.63316168e-05, -4.47856262e-04],\n","        [ 9.28321169e-05,  2.77412211e-04, -5.42914262e-04, ...,\n","         -2.06388955e-04,  7.95713204e-05, -5.46652358e-04],\n","        [ 1.08689288e-04,  2.56368541e-04, -6.72587543e-04, ...,\n","         -1.78192407e-04,  8.53065576e-05, -6.58175792e-04]]],\n","      dtype=float32)>"]},"metadata":{},"execution_count":13}],"source":["# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n","# 지금은 동작 원리에 너무 빠져들지 마세요~\n","for src_sample, tgt_sample in dataset.take(1): break\n","\n","# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n","model(src_sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1652954638299,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"IZHAUwpPD0Tb","outputId":"5ec314db-1901-4d15-b03e-ff7bb4547cb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"text_generator\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  1792256   \n","                                                                 \n"," lstm (LSTM)                 multiple                  197120    \n","                                                                 \n"," lstm_1 (LSTM)               multiple                  131584    \n","                                                                 \n"," lstm_2 (LSTM)               multiple                  131584    \n","                                                                 \n"," lstm_3 (LSTM)               multiple                  131584    \n","                                                                 \n"," dropout (Dropout)           multiple                  0         \n","                                                                 \n"," dense (Dense)               multiple                  903129    \n","                                                                 \n","=================================================================\n","Total params: 3,287,257\n","Trainable params: 3,287,257\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55035,"status":"ok","timestamp":1652954693323,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"8uDXxsqAEAHX","outputId":"45ca7435-b32a-40c3-bee9-cf3a4cc0f350"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","92/92 [==============================] - 10s 20ms/step - loss: 5.5931\n","Epoch 2/30\n","92/92 [==============================] - 2s 19ms/step - loss: 4.7751\n","Epoch 3/30\n","92/92 [==============================] - 2s 19ms/step - loss: 4.7516\n","Epoch 4/30\n","92/92 [==============================] - 2s 19ms/step - loss: 4.6562\n","Epoch 5/30\n","92/92 [==============================] - 2s 16ms/step - loss: 4.5157\n","Epoch 6/30\n","92/92 [==============================] - 2s 16ms/step - loss: 4.4391\n","Epoch 7/30\n","92/92 [==============================] - 2s 16ms/step - loss: 4.4112\n","Epoch 8/30\n","92/92 [==============================] - 2s 16ms/step - loss: 4.3986\n","Epoch 9/30\n","92/92 [==============================] - 2s 16ms/step - loss: 4.2776\n","Epoch 10/30\n","92/92 [==============================] - 2s 16ms/step - loss: 4.1293\n","Epoch 11/30\n","92/92 [==============================] - 2s 16ms/step - loss: 4.0775\n","Epoch 12/30\n","92/92 [==============================] - 2s 16ms/step - loss: 4.0491\n","Epoch 13/30\n","92/92 [==============================] - 2s 16ms/step - loss: 4.0258\n","Epoch 14/30\n","92/92 [==============================] - 2s 16ms/step - loss: 4.0037\n","Epoch 15/30\n","92/92 [==============================] - 2s 16ms/step - loss: 3.9793\n","Epoch 16/30\n","92/92 [==============================] - 2s 16ms/step - loss: 3.9526\n","Epoch 17/30\n","92/92 [==============================] - 2s 16ms/step - loss: 3.9293\n","Epoch 18/30\n","92/92 [==============================] - 2s 16ms/step - loss: 3.9101\n","Epoch 19/30\n","92/92 [==============================] - 2s 16ms/step - loss: 3.8924\n","Epoch 20/30\n","92/92 [==============================] - 2s 17ms/step - loss: 3.8780\n","Epoch 21/30\n","92/92 [==============================] - 2s 16ms/step - loss: 3.8617\n","Epoch 22/30\n","92/92 [==============================] - 2s 16ms/step - loss: 3.8475\n","Epoch 23/30\n","92/92 [==============================] - 2s 16ms/step - loss: 3.8310\n","Epoch 24/30\n","92/92 [==============================] - 2s 16ms/step - loss: 3.8164\n","Epoch 25/30\n","92/92 [==============================] - 2s 16ms/step - loss: 3.8021\n","Epoch 26/30\n","92/92 [==============================] - 2s 17ms/step - loss: 3.7866\n","Epoch 27/30\n","92/92 [==============================] - 2s 16ms/step - loss: 3.7725\n","Epoch 28/30\n","92/92 [==============================] - 2s 16ms/step - loss: 3.7564\n","Epoch 29/30\n","92/92 [==============================] - 2s 17ms/step - loss: 3.7405\n","Epoch 30/30\n","92/92 [==============================] - 2s 17ms/step - loss: 3.7268\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2dc84fae90>"]},"metadata":{},"execution_count":15}],"source":["# optimizer와 loss등은 차차 배웁니다\n","# 혹시 미리 알고 싶다면 아래 문서를 참고하세요\n","# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n","# https://www.tensorflow.org/api_docs/python/tf/keras/losses\n","# 양이 상당히 많은 편이니 지금 보는 것은 추천하지 않습니다\n","optimizer = tf.keras.optimizers.Adam()\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True,\n","    reduction='none'\n",")\n","\n","model.compile(loss=loss, optimizer=optimizer)\n","model.fit(dataset, epochs=30)"]},{"cell_type":"code","source":["results = model.evaluate(enc_val,  dec_val, verbose=2)\n","\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-GozLO5YlMN","executionInfo":{"status":"ok","timestamp":1652954695971,"user_tz":-540,"elapsed":2655,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"39bafd56-a0f6-4dd1-9b36-6170650a8ccb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["148/148 - 3s - loss: 6.0263 - 3s/epoch - 17ms/step\n","6.026282787322998\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jznOmUtsEMOD"},"outputs":[],"source":["def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n","    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n","    test_input = tokenizer.texts_to_sequences([init_sentence])\n","    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n","    end_token = tokenizer.word_index[\"<end>\"]\n","\n","    # 단어 하나씩 예측해 문장을 만듭니다\n","    #    1. 입력받은 문장의 텐서를 입력합니다\n","    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n","    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n","    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n","    while True:\n","        # 1\n","        predict = model(test_tensor) \n","        # 2\n","        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n","        # 3 \n","        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n","        # 4\n","        if predict_word.numpy()[0] == end_token: break\n","        if test_tensor.shape[1] >= max_len: break\n","\n","    generated = \"\"\n","    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n","    for word_index in test_tensor[0].numpy():\n","        generated += tokenizer.index_word[word_index] + \" \"\n","\n","    return generated"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1303,"status":"ok","timestamp":1652954697269,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"an50Ah15Hve7","outputId":"48ea1756-b166-4626-cb42-c7092564def4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<start> he , the <unk> , and the <unk> , <end> '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}],"source":["generate_text(model, tokenizer, init_sentence=\"<start> he\")"]},{"cell_type":"markdown","source":["# 프로젝트 : 멋진 작사가 만들기"],"metadata":{"id":"OHBN--vWsLsv"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2988,"status":"ok","timestamp":1653021257436,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"dofBFYbIIliZ","outputId":"b6071306-c10c-48fc-eaa0-44769a5f4dc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["glob2                         0.7\n","2.8.0\n"]}],"source":["import glob\n","import tensorflow\n","\n","!pip list | grep glob\n","print(tensorflow.__version__)"]},{"cell_type":"markdown","source":["데이터 읽기"],"metadata":{"id":"hCHPqSjRSRJ0"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17248,"status":"ok","timestamp":1653021290317,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"},"user_tz":-540},"id":"6Td876akIpUj","outputId":"84b24993-0ff5-4c83-9281-2747577ebe31"},"outputs":[{"output_type":"stream","name":"stdout","text":["데이터 크기: 187088\n","Examples:\n"," ['THE QUEEN _of_ HEARTS', '', '']\n"]}],"source":["import glob\n","import os\n","\n","txt_file_path = '/content/drive/MyDrive/AIFFEL/EXP/*text/data/data/lyrics/*'\n","\n","txt_list = glob.glob(txt_file_path)\n","# txt_list\n","raw_corpus = []\n","\n","# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n","for txt_file in txt_list:\n","    with open(txt_file, \"r\") as f:\n","        raw = f.read().splitlines()\n","        raw_corpus.extend(raw)\n","\n","print(\"데이터 크기:\", len(raw_corpus))\n","print(\"Examples:\\n\", raw_corpus[:3])"]},{"cell_type":"markdown","source":["데이터 정제"],"metadata":{"id":"YsH4rX5nXfM9"}},{"cell_type":"code","source":["for idx, sentence in enumerate(raw_corpus):\n","    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n","    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n","\n","    if idx > 10: break   # 일단 문장 10개만 확인해 볼 겁니다.\n","        \n","    print(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wskTPUcSd2A","executionInfo":{"status":"ok","timestamp":1653021293634,"user_tz":-540,"elapsed":266,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"38238407-78f4-4eb6-fe2a-446f439f4332"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["THE QUEEN _of_ HEARTS\n","    The Queen of Hearts she made some tarts,\n","      All on a summer's day;\n","    The Knave of Hearts he stole those tarts,\n","      And took them clean away.\n","    The King of Hearts called for those tarts,\n","    And beat the Knave full sore.\n"]}]},{"cell_type":"code","source":["import re\n","\n","# 입력된 문장을\n","#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n","#     2. 특수문자 양쪽에 공백을 넣고\n","#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n","#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n","#     5. 다시 양쪽 공백을 지웁니다\n","#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n","# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n","def preprocess_sentence(sentence):\n","    sentence = sentence.lower().strip() # 1\n","    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n","    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n","    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n","    sentence = sentence.strip() # 5\n","    sentence = '<start> ' + sentence + ' <end>' # 6\n","    return sentence\n","\n","# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n","print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tnkd9wc4SdyJ","executionInfo":{"status":"ok","timestamp":1653021294828,"user_tz":-540,"elapsed":2,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"924f9662-0ec1-4caf-bb4f-d535b345876c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["<start> this is sample sentence . <end>\n"]}]},{"cell_type":"code","source":["# 여기에 정제된 문장을 모을겁니다\n","corpus = []\n","\n","for sentence in raw_corpus:\n","    # 우리가 원하지 않는 문장은 건너뜁니다\n","    if len(sentence) == 0: continue\n","    if sentence[-1] == \":\": continue\n","    \n","    \n","    # 정제를 하고 담아주세요\n","    preprocessed_sentence = preprocess_sentence(sentence)\n","    corpus.append(preprocessed_sentence)\n","        \n","# 정제된 결과를 10개만 확인해보죠\n","corpus[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AuNI34HMSdu4","executionInfo":{"status":"ok","timestamp":1653021297898,"user_tz":-540,"elapsed":1888,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"b9013fc5-d1b1-47d6-fa6a-9f31f0b677bf"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<start> the queen of hearts <end>',\n"," '<start> the queen of hearts she made some tarts , <end>',\n"," '<start> all on a summer s day <end>',\n"," '<start> the knave of hearts he stole those tarts , <end>',\n"," '<start> and took them clean away . <end>',\n"," '<start> the king of hearts called for those tarts , <end>',\n"," '<start> and beat the knave full sore . <end>',\n"," '<start> the knave of hearts brought back those tarts , <end>',\n"," '<start> and vowed he d steal no more . <end>',\n"," '<start> saint swithin s day <end>']"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용합니다\n","# 더 잘 알기 위해 아래 문서들을 참고하면 좋습니다\n","# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n","# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n","def tokenize(corpus):\n","    # 7000단어를 기억할 수 있는 tokenizer를 만들겁니다\n","    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n","    # 15000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","        num_words=20000, \n","        filters=' ',\n","        oov_token=\"<unk>\"\n","    )\n","    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n","    tokenizer.fit_on_texts(corpus)\n","    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n","    tensor = tokenizer.texts_to_sequences(corpus)   \n","    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n","    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n","    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen = 16)  \n","    \n","    print(tensor,tokenizer)\n","    return tensor, tokenizer\n","\n","tensor, tokenizer = tokenize(corpus)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7s4T-bHiSdrZ","executionInfo":{"status":"ok","timestamp":1653021302754,"user_tz":-540,"elapsed":3648,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"8d59ceda-3b1b-4c2e-f057-69a5c7106187"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[[  2   6 818 ...   0   0   0]\n"," [  2   6 818 ...   0   0   0]\n"," [  2  24  18 ...   0   0   0]\n"," ...\n"," [  2   5  90 ...   0   0   0]\n"," [  2   9 157 ...   0   0   0]\n"," [  2 160  15 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7fb815a85fd0>\n"]}]},{"cell_type":"code","source":["for idx in tokenizer.index_word:\n","    print(idx, \":\", tokenizer.index_word[idx])\n","\n","    if idx >= 10: break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2xekxrd2Sdnh","executionInfo":{"status":"ok","timestamp":1653021304155,"user_tz":-540,"elapsed":269,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"d9ed61dc-4e8e-4988-b349-2422af563282"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["1 : <unk>\n","2 : <start>\n","3 : <end>\n","4 : ,\n","5 : i\n","6 : the\n","7 : you\n","8 : and\n","9 : a\n","10 : to\n"]}]},{"cell_type":"markdown","source":["모델 만들기"],"metadata":{"id":"Gbsuidc8TRD_"}},{"cell_type":"code","source":["# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n","# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n","src_input = tensor[:, :-1]  \n","# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n","tgt_input = tensor[:, 1:]    \n","\n","print(src_input[0])\n","print(tgt_input[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8mr8bpcSdPe","executionInfo":{"status":"ok","timestamp":1653021306261,"user_tz":-540,"elapsed":3,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"c7af121d-2d2c-4726-c468-7313795479b9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[  2   6 818  19 953   3   0   0   0   0   0   0   0   0   0]\n","[  6 818  19 953   3   0   0   0   0   0   0   0   0   0   0]\n"]}]},{"cell_type":"code","source":["BUFFER_SIZE = len(src_input)\n","BATCH_SIZE = 256\n","steps_per_epoch = len(src_input) // BATCH_SIZE\n","\n"," # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n","VOCAB_SIZE = tokenizer.num_words + 1   \n","\n","# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n","# 데이터셋에 대해서는 아래 문서를 참고하세요\n","# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n","# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n","\n","dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n","dataset = dataset.shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n","dataset\n","\n","# dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n","# dataset = dataset.shuffle(BUFFER_SIZE)\n","# dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n","# dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L0X9Lcw_XSfx","executionInfo":{"status":"ok","timestamp":1653021311191,"user_tz":-540,"elapsed":3407,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"cc5f45d7-6c7c-40cf-e24b-5331bb4229a4"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BatchDataset element_spec=(TensorSpec(shape=(256, 15), dtype=tf.int32, name=None), TensorSpec(shape=(256, 15), dtype=tf.int32, name=None))>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","enc_train, enc_val, dec_train, dec_val = train_test_split( src_input, tgt_input, test_size=0.2, random_state=2)"],"metadata":{"id":"aB838AxMjo97","executionInfo":{"status":"ok","timestamp":1653021312867,"user_tz":-540,"elapsed":404,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["train data"],"metadata":{"id":"YxUzyLSPUcIy"}},{"cell_type":"code","source":["train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n","train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n","train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNB6faEgjryM","executionInfo":{"status":"ok","timestamp":1653021315296,"user_tz":-540,"elapsed":282,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"e3765907-9b45-4b37-fb3a-f8d1f81a0d30"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BatchDataset element_spec=(TensorSpec(shape=(256, 15), dtype=tf.int32, name=None), TensorSpec(shape=(256, 15), dtype=tf.int32, name=None))>"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["test data"],"metadata":{"id":"32W_ZMJnUfuy"}},{"cell_type":"code","source":["val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n","val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n","val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n","val_dataset"],"metadata":{"id":"JKZLsi4kK9gI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653021319019,"user_tz":-540,"elapsed":288,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"3b9e2cc5-4463-404f-9580-bddcd22fcae9"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BatchDataset element_spec=(TensorSpec(shape=(256, 15), dtype=tf.int32, name=None), TensorSpec(shape=(256, 15), dtype=tf.int32, name=None))>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# class TextGenerator(tf.keras.Model):\n","#     def __init__(self, vocab_size, embedding_size, hidden_size):\n","#         super().__init__()\n","        \n","#         self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n","#         self.rnn_1 = tf.keras.layers.LSTM(units = 128, return_sequences=True)\n","#         self.rnn_2 = tf.keras.layers.LSTM(units = 64, return_sequences=True)\n","#         self.rnn_3 = tf.keras.layers.LSTM(units = 64, return_sequences=True)\n","#         self.rnn_4 = tf.keras.layers.LSTM(units = 64 , return_sequences=True)\n","#         self.rnn_5 = tf.keras.layers.LSTM(units = 32 , return_sequences=True)\n","#         self.drop  = tf.keras.layers.Dropout(0.5)\n","#         self.linear = tf.keras.layers.Dense(vocab_size)\n","        \n","#     def call(self, x):\n","#         out = self.embedding(x)\n","#         out = self.rnn_1(out)\n","#         out = self.rnn_2(out)\n","#         out = self.rnn_3(out)\n","#         out = self.rnn_4(out)\n","#         out = self.rnn_5(out)\n","#         out = self.drop(out)\n","#         out = self.linear(out)\n","        \n","#         return out\n","    \n","# embedding_size = 256\n","# hidden_size = 1024\n","# model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"],"metadata":{"id":"-ZD4D5GnXScc","executionInfo":{"status":"ok","timestamp":1653021320528,"user_tz":-540,"elapsed":283,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["Model : Embedding layer - LSTM - LSTM - Dense"],"metadata":{"id":"Tt1yXFtVUiqj"}},{"cell_type":"code","source":["class TextGenerator(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_size, hidden_size):\n","        super().__init__()\n","        \n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n","        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n","        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n","        self.rnn_3 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n","        self.linear = tf.keras.layers.Dense(vocab_size)\n","        \n","    def call(self, x):\n","        out = self.embedding(x)\n","        out = self.rnn_1(out)\n","        out = self.rnn_2(out)\n","        out = self.rnn_3(out)\n","        out = self.linear(out)\n","        \n","        return out\n","    \n","embedding_size = 512\n","hidden_size = 1024\n","model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"],"metadata":{"id":"4k72lacxVmod","executionInfo":{"status":"ok","timestamp":1653023361098,"user_tz":-540,"elapsed":394,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n","# 지금은 동작 원리에 너무 빠져들지 마세요~\n","for src_sample, tgt_sample in dataset.take(1): break\n","\n","# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n","model(src_sample)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RFsFtK_XSYu","executionInfo":{"status":"ok","timestamp":1653023365837,"user_tz":-540,"elapsed":2817,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"ba80288d-aea6-48c6-a3a1-114b6b1ebde1"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(256, 15, 20001), dtype=float32, numpy=\n","array([[[ 6.69463952e-06, -1.82858457e-05, -1.39801223e-05, ...,\n","          9.91448542e-06,  2.91215765e-05,  3.11503427e-05],\n","        [-1.05817126e-05,  3.48311869e-06, -2.57709198e-05, ...,\n","          4.57393762e-05,  5.86533715e-05,  5.90081072e-05],\n","        [-6.98880613e-05,  6.63547107e-05, -6.65963162e-05, ...,\n","          5.94711601e-05,  5.05249591e-05,  7.12204856e-05],\n","        ...,\n","        [ 1.10658782e-03,  8.09071935e-04, -4.14307695e-04, ...,\n","          5.48216398e-04, -1.22786034e-03,  5.03679854e-04],\n","        [ 1.41406560e-03,  8.09527352e-04, -4.76389978e-04, ...,\n","          6.02879270e-04, -1.40215014e-03,  6.12686155e-04],\n","        [ 1.70619704e-03,  7.91847240e-04, -5.41874149e-04, ...,\n","          6.38786179e-04, -1.55658193e-03,  7.24436191e-04]],\n","\n","       [[ 6.69463952e-06, -1.82858457e-05, -1.39801223e-05, ...,\n","          9.91448542e-06,  2.91215765e-05,  3.11503427e-05],\n","        [ 5.78785039e-05,  7.83732321e-06, -2.82871042e-05, ...,\n","          3.49123729e-05,  9.15344863e-05,  4.10241919e-05],\n","        [ 1.43452169e-04,  5.01310351e-05, -4.36934024e-05, ...,\n","          1.37849085e-04,  1.37229552e-04,  2.87623352e-05],\n","        ...,\n","        [ 1.45135145e-03,  4.44179837e-04,  2.38466600e-04, ...,\n","          8.93097778e-04, -6.00747298e-04,  6.15903409e-04],\n","        [ 1.68190675e-03,  4.72761953e-04,  2.15103690e-04, ...,\n","          9.14450211e-04, -8.04121955e-04,  7.21170334e-04],\n","        [ 1.90832943e-03,  4.83290700e-04,  1.68718267e-04, ...,\n","          9.20425053e-04, -9.99474782e-04,  8.27391050e-04]],\n","\n","       [[ 6.69463952e-06, -1.82858457e-05, -1.39801223e-05, ...,\n","          9.91448542e-06,  2.91215765e-05,  3.11503427e-05],\n","        [ 5.78785039e-05,  7.83732321e-06, -2.82871042e-05, ...,\n","          3.49123729e-05,  9.15344863e-05,  4.10241919e-05],\n","        [ 1.39415453e-04,  3.54538533e-05, -9.45197680e-05, ...,\n","          1.00083191e-04,  1.76787522e-04,  3.89829402e-05],\n","        ...,\n","        [-1.63231180e-05,  3.28492024e-05, -1.43935424e-04, ...,\n","         -7.26667640e-05,  1.38702104e-04,  1.05293315e-04],\n","        [-2.45275514e-05,  5.12343468e-05, -7.09227243e-05, ...,\n","         -7.49405372e-05, -2.97294519e-05,  2.51632853e-04],\n","        [ 5.42054477e-05,  9.89293403e-05, -2.34674690e-06, ...,\n","         -4.59876828e-05, -2.28945675e-04,  3.98078177e-04]],\n","\n","       ...,\n","\n","       [[ 1.31776033e-05,  5.44062787e-05,  6.67800168e-06, ...,\n","          2.28383997e-05,  4.30489199e-05, -2.13394924e-05],\n","        [ 2.52260434e-05,  1.06698855e-04,  1.75138284e-05, ...,\n","          7.62158597e-05,  1.26699771e-04, -8.74922262e-05],\n","        [ 5.55073493e-05,  1.66821701e-04, -1.26585655e-05, ...,\n","          1.00495352e-04,  2.11281600e-04, -1.52683948e-04],\n","        ...,\n","        [ 5.76262770e-04,  8.26216943e-04, -3.29614966e-04, ...,\n","         -9.12630756e-04,  4.07167739e-04,  2.02465992e-04],\n","        [ 4.61729767e-04,  8.15447362e-04, -2.72055273e-04, ...,\n","         -9.23361396e-04,  3.17890343e-04,  2.08087731e-04],\n","        [ 3.94280709e-04,  7.36751535e-04, -2.35645275e-04, ...,\n","         -9.06263711e-04,  1.72187225e-04,  2.36270047e-04]],\n","\n","       [[ 6.69463952e-06, -1.82858457e-05, -1.39801223e-05, ...,\n","          9.91448542e-06,  2.91215765e-05,  3.11503427e-05],\n","        [ 1.78632599e-05, -9.89461987e-05, -5.87019940e-06, ...,\n","          1.08364711e-05,  1.08203625e-04,  7.18445081e-05],\n","        [ 1.45807408e-05, -2.18291301e-04,  2.07331777e-05, ...,\n","          2.07611611e-05,  1.78223607e-04,  1.12966532e-04],\n","        ...,\n","        [ 1.26974413e-03,  1.36377668e-04,  3.21449988e-05, ...,\n","          3.78601515e-04, -1.56011223e-03,  8.37688451e-04],\n","        [ 1.51471526e-03,  1.98055553e-04, -2.02594238e-05, ...,\n","          4.42530640e-04, -1.72189123e-03,  8.87529575e-04],\n","        [ 1.75751455e-03,  2.38981505e-04, -8.41059009e-05, ...,\n","          4.92092106e-04, -1.85528689e-03,  9.44730768e-04]],\n","\n","       [[ 6.69463952e-06, -1.82858457e-05, -1.39801223e-05, ...,\n","          9.91448542e-06,  2.91215765e-05,  3.11503427e-05],\n","        [-6.22396255e-05, -1.67232258e-06, -2.32961956e-05, ...,\n","          3.64301486e-05,  3.96393443e-05,  6.73737813e-05],\n","        [-1.70068131e-04,  1.22094907e-05, -7.96445602e-06, ...,\n","          7.77222740e-05,  2.34441050e-05,  1.16173062e-04],\n","        ...,\n","        [ 5.03160583e-04,  7.29602471e-04, -1.94561271e-05, ...,\n","          6.38130587e-05, -2.35309795e-04,  7.35374459e-04],\n","        [ 7.37072609e-04,  7.53354456e-04, -6.61737286e-05, ...,\n","          1.32877583e-04, -3.78394820e-04,  7.81814626e-04],\n","        [ 9.88992513e-04,  7.49278290e-04, -1.25626320e-04, ...,\n","          2.03144169e-04, -5.43441565e-04,  8.32741265e-04]]],\n","      dtype=float32)>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lGPgO0V7XSUa","executionInfo":{"status":"ok","timestamp":1653023369024,"user_tz":-540,"elapsed":1012,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"78d129df-0c47-4a07-f985-ce930285e971"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"text_generator_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     multiple                  10240512  \n","                                                                 \n"," lstm_2 (LSTM)               multiple                  6295552   \n","                                                                 \n"," lstm_3 (LSTM)               multiple                  8392704   \n","                                                                 \n"," lstm_4 (LSTM)               multiple                  8392704   \n","                                                                 \n"," dense_1 (Dense)             multiple                  20501025  \n","                                                                 \n","=================================================================\n","Total params: 53,822,497\n","Trainable params: 53,822,497\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# optimizer와 loss등은 차차 배웁니다\n","# 혹시 미리 알고 싶다면 아래 문서를 참고하세요\n","# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n","# https://www.tensorflow.org/api_docs/python/tf/keras/losses\n","# 양이 상당히 많은 편이니 지금 보는 것은 추천하지 않습니다\n","optimizer = tf.keras.optimizers.Adam()\n","#Loss\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","model.compile(loss=loss, optimizer=optimizer)\n","\n","model.fit(train_dataset, epochs=10, validation_data=val_dataset)"],"metadata":{"id":"3JjOMAwvEAq4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653024328609,"user_tz":-540,"elapsed":958395,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"d10e0868-6aa2-4b36-d695-35d542f1d106"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","549/549 [==============================] - 99s 175ms/step - loss: 3.7106 - val_loss: 3.3655\n","Epoch 2/10\n","549/549 [==============================] - 95s 174ms/step - loss: 3.2128 - val_loss: 3.1460\n","Epoch 3/10\n","549/549 [==============================] - 95s 174ms/step - loss: 3.0349 - val_loss: 3.0337\n","Epoch 4/10\n","549/549 [==============================] - 95s 174ms/step - loss: 2.9077 - val_loss: 2.9480\n","Epoch 5/10\n","549/549 [==============================] - 95s 174ms/step - loss: 2.8040 - val_loss: 2.8835\n","Epoch 6/10\n","549/549 [==============================] - 95s 174ms/step - loss: 2.7156 - val_loss: 2.8351\n","Epoch 7/10\n","549/549 [==============================] - 95s 173ms/step - loss: 2.6361 - val_loss: 2.7940\n","Epoch 8/10\n","549/549 [==============================] - 95s 174ms/step - loss: 2.5621 - val_loss: 2.7610\n","Epoch 9/10\n","549/549 [==============================] - 95s 174ms/step - loss: 2.4925 - val_loss: 2.7329\n","Epoch 10/10\n","549/549 [==============================] - 95s 173ms/step - loss: 2.4265 - val_loss: 2.7102\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb7966658d0>"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["results = model.evaluate(enc_val,  dec_val, verbose=2)\n","\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qeRlohNVoRnH","executionInfo":{"status":"ok","timestamp":1653026518722,"user_tz":-540,"elapsed":14687,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"9dab2d20-5dbd-4130-f9d1-df61ef48297e"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["1099/1099 - 14s - loss: 2.7104 - 14s/epoch - 13ms/step\n","2.710362434387207\n"]}]},{"cell_type":"code","source":["def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n","    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n","    test_input = tokenizer.texts_to_sequences([init_sentence])\n","    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n","    end_token = tokenizer.word_index[\"<end>\"]\n","\n","    # 단어 하나씩 예측해 문장을 만듭니다\n","    #    1. 입력받은 문장의 텐서를 입력합니다\n","    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n","    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n","    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n","    while True:\n","        # 1\n","        predict = model(test_tensor) \n","        # 2\n","        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n","        # 3 \n","        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n","        # 4\n","        if predict_word.numpy()[0] == end_token: break\n","        if test_tensor.shape[1] >= max_len: break\n","\n","    generated = \"\"\n","    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n","    for word_index in test_tensor[0].numpy():\n","        generated += tokenizer.index_word[word_index] + \" \"\n","\n","    return generated"],"metadata":{"id":"3QwP_ApMoY7T","executionInfo":{"status":"ok","timestamp":1653026518722,"user_tz":-540,"elapsed":9,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["generate_text(model, tokenizer, init_sentence=\"<start> sky \", max_len=20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"J4WU0qg8oY23","executionInfo":{"status":"ok","timestamp":1653026522847,"user_tz":-540,"elapsed":292,"user":{"displayName":"Sehan Lee","userId":"12512051884908843605"}},"outputId":"9a24b2aa-3e4a-480c-9d56-12b3a5478766"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<start> sky is the limit and you know that you can <end> '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":[""],"metadata":{"id":"f1UElw5XS-CN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.Train data와 evalution data로 분리하지 않고 source 데이타와 target데이터로 분리하였더니 매우 높은 평가 값이 나왔지만 evalution 데이터를 넣었더니 매우 낮은 값을 얻을 수 있었다.  \n","\n","2. 데이터 수정하는 과정에서 dataset을 tensor_slice, shuffle, 그리고 batch 하는 과정에서 동일한 이름의 dataset 이름을 적어 놓아야 하는데 그렇지 못하여 shape(256, 16)이어야 하는데 다른 dataset으로 하였는데 기존 데이터와 겹치면서 (256, 256, 16)으로 나와 model.fit이 실행이 안 되었다. 한 줄 한 줄 하나씩 보는 것이 중요한 것을 알 수 있었다."],"metadata":{"id":"dgCqBSj_U7OI"}}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"[E6]text.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1cpTQevvGWpCB91OIY5OkZW5QN5ie4fe-","authorship_tag":"ABX9TyOfDuO/drjNGwcH/HxTjOdy"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}